{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fc15214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q \"dlt[qdrant]\" \"qdrant-client[fastembed]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "614d5020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[39mdlt 1.15.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!dlt --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b736e51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import dlt\n",
    "from dlt.destinations import qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42f36d0",
   "metadata": {},
   "source": [
    "## What dlt is\n",
    "\n",
    "**dlt** is a Python library for building **ELT/ETL** pipelines with minimal boilerplate. You write a **resource** (a function that produces rows/frames/chunks), and a **pipeline** (where to load them). dlt takes care of schema inference, typing, creating tables, and loading into a destination (here: **Qdrant DB**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f81410",
   "metadata": {},
   "source": [
    "* `@dlt.resource(...)` turns the function into a **resource**—a producer of data for dlt to load.\n",
    "* **`name=\"zoomcamp_table\"`**: the **resource name**. By default this becomes the **table name** in the destination.\n",
    "* **`write_disposition=\"replace\"`**: loading behavior. On each run, **drop/recreate** the table and load fresh data. (Dangerous if you expect to accumulate history; use `append` to keep growing, or `merge` when you have keys.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf6aecb",
   "metadata": {},
   "source": [
    "### Why **`yield`** and not `return`?\n",
    "\n",
    "Short version: **streaming, robustness, and scale**.\n",
    "\n",
    "* **Streaming / memory-safety**: With `yield`, you can emit data in **chunks** (e.g., pages from an API, monthly partitions) so your process doesn’t hold everything in RAM.\n",
    "* **Resumability**: dlt can checkpoint between chunks. If a run fails mid-load, you don’t restart from scratch.\n",
    "* **Throughput**: dlt can prepare/flush chunks to the destination while you compute the next one.\n",
    "* **Schema inference**: It infers schema from the first item/chunk and keeps loading—safer for big jobs.\n",
    "\n",
    "`return df` is fine for tiny datasets, but it’s a foot-gun once data grows. Use `yield` by default; scale pain disappears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4894e0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dlt.resource(write_disposition='replace', name='zoomcamp_table')\n",
    "def zoomcamp_data():\n",
    "    docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "    docs_response = requests.get(docs_url)\n",
    "    documents_raw = docs_response.json()\n",
    "\n",
    "    for course in documents_raw:\n",
    "        course_name = course['course']\n",
    "\n",
    "        for doc in course['documents']:\n",
    "            doc['course'] = course_name\n",
    "            yield doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0220919",
   "metadata": {},
   "source": [
    "Creates a **pipeline** specifying where and how to load.\n",
    "\n",
    "  * **`pipeline_name`**: a unique id for the pipeline; used for state and local files.\n",
    "  * **`destination=qdrant_destination`**: load into a local **Qdrant DB** database file. \n",
    "  * **`dataset_name=\"zoomcamp_schema\"`**: logical **schema/namespace** in the destination. This is the schema; your table becomes `zoomcamp_schema.zoomcamp_table`.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "load_info = pipeline.run(zoomcamp_data()) \n",
    "```\n",
    "**`load_info`**: structured result (load id, tables written, row counts, any state updates). Useful for logging/CI.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "print(pipeline.last_trace)\n",
    "```\n",
    "Prints the diagnostic trace of the **last run**—handy for debugging (tables created, rows loaded, timings, warnings, errors).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48537bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 5 files: 100%|██████████| 5/5 [00:03<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline zoomcamp_pipeline load step completed in 4.36 seconds\n",
      "1 load package(s) were loaded to destination qdrant and into dataset zoomcamp_schema\n",
      "The qdrant destination used /workspaces/LLM-Zoomcamp/dlt-workshop/db.qdrant location to store data\n",
      "Load package 1755468689.8987837 is LOADED and contains no failed jobs\n",
      "Run started at 2025-08-17 22:11:23.995365+00:00 and COMPLETED in 10.83 seconds with 4 steps.\n",
      "Step extract COMPLETED in 0.47 seconds.\n",
      "\n",
      "Load package 1755468689.8987837 is EXTRACTED and NOT YET LOADED to the destination and contains no failed jobs\n",
      "\n",
      "Step normalize COMPLETED in 0.08 seconds.\n",
      "Normalized data for the following tables:\n",
      "- _dlt_pipeline_state: 1 row(s)\n",
      "- zoomcamp_table: 948 row(s)\n",
      "\n",
      "Load package 1755468689.8987837 is NORMALIZED and NOT YET LOADED to the destination and contains no failed jobs\n",
      "\n",
      "Step load COMPLETED in 4.37 seconds.\n",
      "Pipeline zoomcamp_pipeline load step completed in 4.36 seconds\n",
      "1 load package(s) were loaded to destination qdrant and into dataset zoomcamp_schema\n",
      "The qdrant destination used /workspaces/LLM-Zoomcamp/dlt-workshop/db.qdrant location to store data\n",
      "Load package 1755468689.8987837 is LOADED and contains no failed jobs\n",
      "\n",
      "Step run COMPLETED in 10.82 seconds.\n",
      "Pipeline zoomcamp_pipeline load step completed in 4.36 seconds\n",
      "1 load package(s) were loaded to destination qdrant and into dataset zoomcamp_schema\n",
      "The qdrant destination used /workspaces/LLM-Zoomcamp/dlt-workshop/db.qdrant location to store data\n",
      "Load package 1755468689.8987837 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "qdrant_destination = qdrant(\n",
    "  qd_path=\"db.qdrant\", \n",
    ")\n",
    "\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name='zoomcamp_pipeline', \n",
    "    destination=qdrant_destination, \n",
    "    dataset_name='zoomcamp_schema'\n",
    ")\n",
    "\n",
    "load_info = pipeline.run(zoomcamp_data())\n",
    "print(load_info)\n",
    "print(pipeline.last_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc1c91c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
